{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from time import perf_counter\n",
    "\n",
    "from mlrose_local import mlrose\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and clean the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are downloaded from Kaggle:<br>\n",
    "nba games https://www.kaggle.com/nathanlauga/nba-games<br>\n",
    "nba_games.csv : All games from 2004 season to last update with the date, teams and some details like number of points, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path into your current working directory\n",
    "os.chdir(r\"C:\\Users\\13102\\Desktop\\CS7641 Machine Learning Randomized Optimization\")\n",
    "\n",
    "nba_games = pd.read_csv('nba_games.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate the different between home team and away team in five aspects, including FG_PCT(field goals percentage), FT_PCT(field throws percentage), FG3_PCT(three-point field goals percentage),AST(assists) and REB(rebounds). HOME_TEAM_WINS represents that if home team wins, the value is 1 and if home team loses, the value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "      <th>FG_PCT_diff</th>\n",
       "      <th>FT_PCT_diff</th>\n",
       "      <th>FG3_PCT_diff</th>\n",
       "      <th>AST_diff</th>\n",
       "      <th>REB_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>965.00000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.54715</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.174093</td>\n",
       "      <td>0.839378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.49803</td>\n",
       "      <td>0.078655</td>\n",
       "      <td>0.146005</td>\n",
       "      <td>0.131647</td>\n",
       "      <td>6.439211</td>\n",
       "      <td>9.418250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.208000</td>\n",
       "      <td>-0.571000</td>\n",
       "      <td>-0.427000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.043000</td>\n",
       "      <td>-0.092000</td>\n",
       "      <td>-0.086000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HOME_TEAM_WINS  FG_PCT_diff  FT_PCT_diff  FG3_PCT_diff    AST_diff  \\\n",
       "count       965.00000   965.000000   965.000000    965.000000  965.000000   \n",
       "mean          0.54715     0.011031     0.001882      0.005033    1.174093   \n",
       "std           0.49803     0.078655     0.146005      0.131647    6.439211   \n",
       "min           0.00000    -0.208000    -0.571000     -0.427000  -22.000000   \n",
       "25%           0.00000    -0.043000    -0.092000     -0.086000   -3.000000   \n",
       "50%           1.00000     0.009000     0.000000      0.003000    1.000000   \n",
       "75%           1.00000     0.068000     0.094000      0.098000    5.000000   \n",
       "max           1.00000     0.258000     0.571000      0.458000   23.000000   \n",
       "\n",
       "         REB_diff  \n",
       "count  965.000000  \n",
       "mean     0.839378  \n",
       "std      9.418250  \n",
       "min    -39.000000  \n",
       "25%     -5.000000  \n",
       "50%      1.000000  \n",
       "75%      7.000000  \n",
       "max     31.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = nba_games[['GAME_DATE_EST','HOME_TEAM_WINS',]]\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Select the data for 2019-2020 season from 2019-10-4 to 2020-3-1\n",
    "start_date='2019-10-4'\n",
    "end_date='2020-3-1'\n",
    "\n",
    "data1['GAME_DATE_EST'] = pd.to_datetime(data1['GAME_DATE_EST'])  \n",
    "mask = (data1['GAME_DATE_EST'] >= start_date) & (data1['GAME_DATE_EST'] <= end_date)\n",
    "data1 = data1.loc[mask]\n",
    "\n",
    "# Drop useless columns\n",
    "data1 = data1.reset_index().drop(columns=['index', 'GAME_DATE_EST'])\n",
    "\n",
    "cols1 = ['FG_PCT','FT_PCT','FG3_PCT','AST','REB']\n",
    "for col in cols1:\n",
    "    data1[col+'_diff'] = nba_games[col+'_home'].sub(nba_games[col+'_away'], axis = 0)\n",
    "\n",
    "# Change datatype from float32 into int64\n",
    "X1 = np.array(data1.values[:,1:-1],dtype='int64')\n",
    "Y1 = np.array(data1.values[:,0],dtype='int64')\n",
    "data1.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X1, Y1, test_size=0.30, random_state=4)\n",
    "\n",
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # One hot encode target values\n",
    "one_hot = OneHotEncoder()\n",
    "y_train_hot = one_hot.fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(y_test.reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run Neural Networks model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, we will compare the fitting time for a neural networks model. Therefore, we only calculate the fitting time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fitting time for NN model = 0.13168369999999996\n",
      "Test fitting time for NN model = 0.0007014000000005183\n",
      "jaccard index:  0.457286432160804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.46      0.51       122\n",
      "           1       0.66      0.75      0.70       168\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       290\n",
      "   macro avg       0.61      0.60      0.60       290\n",
      "weighted avg       0.62      0.63      0.62       290\n",
      " samples avg       0.63      0.63      0.63       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train Model using MLPClassifier function on Relu Activation Function\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(9,9), activation = 'relu', max_iter=1000, solver = 'lbfgs' )\n",
    "time_start = perf_counter()\n",
    "clf.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'Train fitting time for NN model = {fit_time}')\n",
    "\n",
    "time_start = perf_counter()\n",
    "yhat = clf.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "print (f'Test fitting time for NN model = {fit_time}')\n",
    "\n",
    "# Evaulation\n",
    "jaccard = jaccard_score(y_test_hot, yhat, average='micro')\n",
    "print(\"jaccard index: \",jaccard)\n",
    "print (classification_report(y_test_hot, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fitting time for NN model = 1.0322408999999997\n",
      "Test fitting time for NN model = 0.0010769999999995505\n",
      "jaccard index:  0.457286432160804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.33      0.41       122\n",
      "           1       0.62      0.81      0.70       168\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       290\n",
      "   macro avg       0.59      0.57      0.56       290\n",
      "weighted avg       0.60      0.61      0.58       290\n",
      " samples avg       0.61      0.61      0.61       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train Model using MLPClassifier function on Sigmoid Activation Function\n",
    "\n",
    "clf_sig = MLPClassifier(hidden_layer_sizes=(9,9), activation = 'logistic', max_iter=1000, solver = 'lbfgs' )\n",
    "time_start = perf_counter()\n",
    "clf_sig.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'Train fitting time for NN model = {fit_time}')\n",
    "\n",
    "time_start = perf_counter()\n",
    "yhat_sig = clf_sig.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "print (f'Test fitting time for NN model = {fit_time}')\n",
    "\n",
    "# Evaulation\n",
    "jaccard_sig = jaccard_score(y_test_hot, yhat_sig, average='micro')\n",
    "print(\"jaccard index: \",jaccard)\n",
    "print (classification_report(y_test_hot, yhat_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Use randomized hill climbing for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fitting time for NN model = 0.23200109999999974\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "clf_hill = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'relu', \n",
    "                                algorithm = 'random_hill_climb', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_hill.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'Train fitting time for NN model = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fitting time for NN model = 0.0009589999999999321\n",
      "accuracy score = 0.6275862068965518\n",
      "f1 score:  0.6196865203761756\n",
      "jaccard index:  0.457286432160804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.46      0.51       122\n",
      "           1       0.66      0.75      0.70       168\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       290\n",
      "   macro avg       0.61      0.60      0.60       290\n",
      "weighted avg       0.62      0.63      0.62       290\n",
      " samples avg       0.63      0.63      0.63       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_hill_test = clf_hill.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy1 = accuracy_score(y_test_hot, yhat_hill_test)\n",
    "f1 = f1_score(y_test_hot, yhat_hill_test, average='weighted') \n",
    "jaccard1 = jaccard_score(y_test_hot, yhat_hill_test, average='micro')\n",
    "print (f'Test fitting time for NN model = {fit_time}')\n",
    "print (f'accuracy score = {test_accuracy1}')\n",
    "print(\"f1 score: \", f1)\n",
    "print(\"jaccard index: \",jaccard1)\n",
    "print (classification_report(y_test_hot, yhat_hill_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fitting time for NN model = 0.5258365000000005\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "clf_hill_sig = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'sigmoid', \n",
    "                                algorithm = 'random_hill_climb', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_hill_sig.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'Train fitting time for NN model = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fitting time for NN model = 0.0006398999999994714\n",
      "accuracy score = 0.6275862068965518\n",
      "f1 score:  0.6196865203761756\n",
      "jaccard index:  0.457286432160804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.46      0.51       122\n",
      "           1       0.66      0.75      0.70       168\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       290\n",
      "   macro avg       0.61      0.60      0.60       290\n",
      "weighted avg       0.62      0.63      0.62       290\n",
      " samples avg       0.63      0.63      0.63       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_hill_test_sig = clf_hill_sig.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy2 = accuracy_score(y_test_hot, yhat_hill_test_sig)\n",
    "f2 = f1_score(y_test_hot, yhat_hill_test_sig, average='weighted') \n",
    "jaccard2 = jaccard_score(y_test_hot, yhat_hill_test_sig, average='micro')\n",
    "print (f'Test fitting time for NN model = {fit_time}')\n",
    "print (f'accuracy score = {test_accuracy2}')\n",
    "print(\"f1 score: \", f2)\n",
    "print(\"jaccard index: \",jaccard2)\n",
    "print (classification_report(y_test_hot, yhat_hill_test_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Use simulated annealing for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search ended with attempts>max_attempts (1000>1000)\n",
      "Train fitting time for NN model = 2.3663499000000012\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "clf_sim = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'relu', \n",
    "                                algorithm = 'simulated_annealing', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_sim.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'Train fitting time for NN model = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fitting time for NN model = 0.0012954999999994499\n",
      "test accuracy score = 0.4206896551724138\n",
      "f1 score:  0.24914630063608975\n",
      "jaccard index:  0.2663755458515284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59       122\n",
      "           1       0.00      0.00      0.00       168\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       290\n",
      "   macro avg       0.21      0.50      0.30       290\n",
      "weighted avg       0.18      0.42      0.25       290\n",
      " samples avg       0.42      0.42      0.42       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_sim_test = clf_sim.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy3 = accuracy_score(y_test_hot, yhat_sim_test)\n",
    "f3 = f1_score(y_test_hot, yhat_sim_test, average='weighted') \n",
    "jaccard3 = jaccard_score(y_test_hot, yhat_sim_test, average='micro')\n",
    "print (f'Test fitting time for NN model = {fit_time}')\n",
    "print (f'test accuracy score = {test_accuracy3}')\n",
    "print(\"f1 score: \", f3)\n",
    "print(\"jaccard index: \",jaccard3)\n",
    "print (classification_report(y_test_hot, yhat_sim_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search ended with attempts>max_attempts (1000>1000)\n",
      "Train fitting time for NN model = 2.2413022\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(7)\n",
    "clf_sim_sig = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'sigmoid', \n",
    "                                algorithm = 'simulated_annealing', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_sim_sig.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'Train fitting time for NN model = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fitting time for NN model = 0.0010329000000002253\n",
      "test accuracy score = 0.6275862068965518\n",
      "f1 score:  0.6196865203761756\n",
      "jaccard index:  0.457286432160804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.46      0.51       122\n",
      "           1       0.66      0.75      0.70       168\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       290\n",
      "   macro avg       0.61      0.60      0.60       290\n",
      "weighted avg       0.62      0.63      0.62       290\n",
      " samples avg       0.63      0.63      0.63       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_sim_test_sig = clf_sim_sig.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy4 = accuracy_score(y_test_hot, yhat_sim_test_sig)\n",
    "f4 = f1_score(y_test_hot, yhat_sim_test_sig, average='weighted') \n",
    "jaccard4 = jaccard_score(y_test_hot, yhat_sim_test_sig, average='micro')\n",
    "print (f'Test fitting time for NN model = {fit_time}')\n",
    "print (f'test accuracy score = {test_accuracy4}')\n",
    "print(\"f1 score: \", f4)\n",
    "print(\"jaccard index: \",jaccard4)\n",
    "print (classification_report(y_test_hot, yhat_sim_test_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Use a genetic algorithm for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search ended with attempts>max_attempts (1000>1000)\n",
      "Train fitting time for NN model = 2.2715651\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "clf_sim = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'relu', \n",
    "                                algorithm = 'simulated_annealing', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_sim.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'Train fitting time for NN model = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fitting time for NN model = 0.0007366000000015305\n",
      "test accuracy score = 0.4206896551724138\n",
      "f1 score:  0.24914630063608975\n",
      "jaccard index:  0.2663755458515284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59       122\n",
      "           1       0.00      0.00      0.00       168\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       290\n",
      "   macro avg       0.21      0.50      0.30       290\n",
      "weighted avg       0.18      0.42      0.25       290\n",
      " samples avg       0.42      0.42      0.42       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_sim_test = clf_sim.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy3 = accuracy_score(y_test_hot, yhat_sim_test)\n",
    "f3 = f1_score(y_test_hot, yhat_sim_test, average='weighted') \n",
    "jaccard3 = jaccard_score(y_test_hot, yhat_sim_test, average='micro')\n",
    "print (f'Test fitting time for NN model = {fit_time}')\n",
    "print (f'test accuracy score = {test_accuracy3}')\n",
    "print(\"f1 score: \", f3)\n",
    "print(\"jaccard index: \",jaccard3)\n",
    "print (classification_report(y_test_hot, yhat_sim_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search ended with attempts>max_attempts (1000>1000)\n",
      "Train fitting time for NN model = 2.2230119000000013\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(7)\n",
    "clf_sim_sig = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'sigmoid', \n",
    "                                algorithm = 'simulated_annealing', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_sim_sig.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'Train fitting time for NN model = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test fitting time for NN model = 0.0007601000000008185\n",
      "test accuracy score = 0.6275862068965518\n",
      "f1 score:  0.6196865203761756\n",
      "jaccard index:  0.457286432160804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.46      0.51       122\n",
      "           1       0.66      0.75      0.70       168\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       290\n",
      "   macro avg       0.61      0.60      0.60       290\n",
      "weighted avg       0.62      0.63      0.62       290\n",
      " samples avg       0.63      0.63      0.63       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_sim_test_sig = clf_sim_sig.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy4 = accuracy_score(y_test_hot, yhat_sim_test_sig)\n",
    "f4 = f1_score(y_test_hot, yhat_sim_test_sig, average='weighted') \n",
    "jaccard4 = jaccard_score(y_test_hot, yhat_sim_test_sig, average='micro')\n",
    "print (f'Test fitting time for NN model = {fit_time}')\n",
    "print (f'test accuracy score = {test_accuracy4}')\n",
    "print(\"f1 score: \", f4)\n",
    "print(\"jaccard index: \",jaccard4)\n",
    "print (classification_report(y_test_hot, yhat_sim_test_sig))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
